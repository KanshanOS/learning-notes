# Elasticsearch 实战

## 基于groovy脚本进行partial update
### 造数据
```json
PUT /test_index/test_type/11
{
  "num":0,
  "tags":[]
}
```

### 内部脚本
```json
POST /test_index/test_type/11/_update
{
  "script": "ctx._source.num+=1"
}
```

### 外部脚本
- 5.x 支持外部脚本，目录：`elasticseach/config/scripts`
- 7.x 不支持外部脚本

## `mget`批量查询
### 查询 `index` 和 `type` 都不同的数据
```json
GET _mget
{
  "docs": [
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": 1
    },
    {
      "_index": "test_index",
      "_type": "test_type",
      "_id": 2
    }
  ]
}
```

### 查询同一个`index`不同`type`数据
```json
GET /test_index/_mget
{
  "docs": [
    {
      "_type": "test_type",
      "_id": 1
    },
    {
      "_type": "test_type",
      "_id": 2
    }
  ]
}
```
### 查询`index`和`type`都相同的数据
```json
GET /test_index/test_type/_mget
{
    "ids": [1, 4]
}
```

## `bulk` 批量增删改
### 功能
> - create : `PUT /index/type/id/_create` 强制创建
> - index : 普通的 PUT 操作，可以创建或者全量替换文档
> - delete : 删除 document
> - update : 执行 partial update 操作
> - **注意：a).bulk api 对 json 的语法有严格的要求，每个json串内部不能换行， 每个json 串之间必须换行； b).bulk 操作中任何一个操作失败了，是不会影响其他的操作的，但是在返回结果中会以异常日志的方式体现； c).`bulk request` 会加载到内存里，如果请求太大的的话，性能反而会下降，因此需要反复尝试出一个最佳的`bulk size`。一般从 1000 - 5000 条数据开始，尝试逐步增加。另一方面，如果看大小的话，最好是在5~15MB之间**

```json
POST /_bulk
{"delete":{"_index":"test_index","_type":"test_type","_id":11}}
{"create":{"_index":"test_index","_type":"test_type","_id":3}}
{"test_field":"test 3"}
{"index":{"_index":"test_index","_type":"test_type","_id":4}}
{"test_field":"replaced test 4"}
{"update":{"_index":"test_index","_type":"test_type","_id":1}}
{"doc":{"test_field":"partial update test 1"}}
```


